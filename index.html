<!DOCTYPE html>
<html lang="en">
    <head>
        <title>HAZ Lab @ Drexel University</title>
        <meta charset="utf-8">
        <meta name="title" content="HAZ Lab @ Drexel University" />
        <meta name="description" content="The HAZ Lab conducts research on Natural Language Processing and Artificial Intelligence, focusing on planning and reasoning using Large Language Models." />
        <meta name="theme-color" content="#fec500" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />

        <link rel="icon" href="favicon.ico" sizes="16x16">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/pure-min.css" />
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/purecss@3.0.0/build/grids-responsive-min.css"/>
        
        <!-- putting these lower so they can override -->
        <link rel="stylesheet" href="style/global.css">
        <link rel="stylesheet" href="style/index.css">
    
    </head>
    <body>
       
    <navbar>
        <span class="hide-mobile">HAZ LAB</span>
        <nav class="nav-links">
            <a href="index.html">home</a>
            <!--<a href="news/index.html">news</a>-->
            <a href="research/index.html">research</a>
            <a href="team/index.html">team</a>
        </nav>
    </navbar>

    <section id="home" class="pure-g">
        <div class="pure-u-1-24"> <!-- Formatting div--> </div>
        <div class="pure-u-md-1-3">
            <p id="splashtext">
                <b>Haz Lab</b> is a research group led by <a href="https://zharry29.github.io/" target="_blank">Prof. Li "Harry" Zhang</a> at Drexel University. We address the lack of verifiability and the danger of hallucination of large language models (LLMs) with the LLM-as-Formalizer paradigm: shifting their role from an unreliable problem solver to a precise translator. The LLM converts natural language input into rigorous formal languages (like PDDL), which are then solved by symbolic solvers, providing verifiability and deterministicity. Such a neuro-symbolic method promises performant and reliable AI systems for high-stakes domains.
                <br><br>
                <strong>I. Auto-Formalization and Tool-Based Problem Solving</strong>
                <br><br>
                Our primary line of work uses LLMs to map specifications of complex reasoning tasks—such as MDP/POMDP planning, constraint satisfaction, or theorem proving—to formal representations like PDDL, SMT, and Lean. These are not only verifiable but also deterministically executable via external solvers. Efforts include benchmarking, test-time and training-time improvements, multimodal and multi-agent formalization, etc.
                <br><br>
                <strong>II. Mechanistic Interpretability</strong>
                <br><br>
                Our secondary line focuses on optimizing the efficiency and fidelity of the LLMs themselves in the abovementioned process. We emply mechanistic interpretability methods such as steering, circuit analysis, etc., to dissect and alter LLMs' behavior in auto-formalization tasks.
            </p>
        </div>
        <div class="pure-u-1-4"> <!-- Formatting div--> </div>
        <div id="logo" class="pure-u-1-3">
            <img src="assets/hazlab_logo.png" alt="HAZ Lab Logo">
        </div>
        <div class="pure-u-1-24"> <!-- Formatting div--> </div>
    </section>


    <!-- 
        <div class="unit dreary block-20" id="visual">
            <img src="/assets/dummy.png" alt="Description" draggable="false">
            <p>Image Caption Goes here</p>
        </div> 
    -->

    <footer style="height: 0px;"></footer>
    </body>
</html>

, 